[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "LCA-Work Visa Trends",
    "section": "",
    "text": "1 Introduction\nThe Labor Condition Applications (LCAs) for VISA types like H-1B, H-1B1, E-3 etc; are released quarterly by the US Department of Labor; the data disclosed includes application details like wage, occupation, and work-site details, etc. We plan to use the latest public disclosures in recent years to explore trends and patterns in work VISA applications.\nTherefore, in this project we will perform an analysis of the data released over the recent years, with a primary focus on H-1B applications. Through these experiments we aim to explore geographic, occupational, temporal, and employer-level patterns in certified and denied applications.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "index.html#research-questions",
    "href": "index.html#research-questions",
    "title": "LCA-Work Visa Trends",
    "section": "1.1 Research questions",
    "text": "1.1 Research questions\n\nGeography: In America, which CBSAs (Core-Based Statistical Area-urban core and the surrounding counties that commute into it) account for the largest shares of certified/approved applications?\nWages by SOC: How are the wage values distributed across various SOC occupations (Standard Occupational Classification) [Eg, 15-1250 Software Developers vs 17-2010 Engineers]?\nTime patterns: What do the monthly trends/patterns of certifications vs denials look like across years, months with higher approval/rejection rates, etc?\nEmployer concentration: How concentrated are the total filings among the top US employers for selected metros or SOCs?\nProcess flow: Timeline/flow of the application process through alluvial plots?",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "2  Data Analysis",
    "section": "",
    "text": "The project aims at an in-depth analysis of Labor Condition Application (LCA) datasets covering U.S. work visas for the years 2019 to 2024. The primary datasets that contain the disclosures consist of 90+ variables for each case including but not limited to the employer, the occupation, the location and the wage. As far as visualization is concerned, we will particularly deal with the statuses of the cases over the course of time, thus getting the CASE_STATUS attribute from every quarterly file (Q1-Q4) and attributing each record with the respective year. The detailed statuses will then be collapsed into broader categories thus treating “Certified” and “Certified – Withdrawn” as the accepted cases and “Denied” and “Withdrawn” as the rejected ones, in order to find out how the approval and denial patterns have shifted over the years.\n\n\nCode\n# Load required libraries\nlibrary(readxl)\nlibrary(dplyr)\nlibrary(ggplot2)\n\noptions(warn = -1)\n\n# Helper function to read only CASE_STATUS column\nread_status_only &lt;- function(file_path, year) {\n  df &lt;- read_excel(file_path, col_types = \"text\")\n  # Keep only CASE_STATUS column and add YEAR\n  df &lt;- df %&gt;% \n    select(CASE_STATUS) %&gt;%\n    mutate(YEAR = year)\n  return(df)\n}\n\n# Read 2019 data\ndf_2019 &lt;- read_status_only(\"data/2019/FY2019.xlsx\", 2019)\n\n# Read 2020 data\ndf_2020_q1 &lt;- read_status_only(\"data/2020/FY2020_Q1.xlsx\", 2020)\ndf_2020_q2 &lt;- read_status_only(\"data/2020/FY2020_Q2.xlsx\", 2020)\ndf_2020_q3 &lt;- read_status_only(\"data/2020/FY2020_Q3.xlsx\", 2020)\ndf_2020_q4 &lt;- read_status_only(\"data/2020/FY2020_Q4.xlsx\", 2020)\ndf_2020 &lt;- bind_rows(df_2020_q1, df_2020_q2, df_2020_q3, df_2020_q4)\nrm(df_2020_q1, df_2020_q2, df_2020_q3, df_2020_q4)\ngc()\n\n\n          used (Mb) gc trigger   (Mb) limit (Mb)  max used   (Mb)\nNcells 1091271 58.3    3548442  189.6         NA   5544440  296.2\nVcells 6452671 49.3  188301112 1436.7      16384 289322900 2207.4\n\n\nCode\n# Read 2021 data\ndf_2021_q1 &lt;- read_status_only(\"data/2021/FY2021_Q1.xlsx\", 2021)\ndf_2021_q2 &lt;- read_status_only(\"data/2021/FY2021_Q2.xlsx\", 2021)\ndf_2021_q3 &lt;- read_status_only(\"data/2021/FY2021_Q3.xlsx\", 2021)\ndf_2021_q4 &lt;- read_status_only(\"data/2021/FY2021_Q4.xlsx\", 2021)\ndf_2021 &lt;- bind_rows(df_2021_q1, df_2021_q2, df_2021_q3, df_2021_q4)\nrm(df_2021_q1, df_2021_q2, df_2021_q3, df_2021_q4)\ngc()\n\n\n          used (Mb) gc trigger   (Mb) limit (Mb)  max used   (Mb)\nNcells 1091778 58.4    3548442  189.6         NA   5544440  296.2\nVcells 8106315 61.9  147006012 1121.6      16384 289322900 2207.4\n\n\nCode\n# Read 2022 data\ndf_2022_q1 &lt;- read_status_only(\"data/2022/FY2022_Q1.xlsx\", 2022)\ndf_2022_q2 &lt;- read_status_only(\"data/2022/FY2022_Q2.xlsx\", 2022)\ndf_2022_q3 &lt;- read_status_only(\"data/2022/FY2022_Q3.xlsx\", 2022)\ndf_2022_q4 &lt;- read_status_only(\"data/2022/FY2022_Q4.xlsx\", 2022)\ndf_2022 &lt;- bind_rows(df_2022_q1, df_2022_q2, df_2022_q3, df_2022_q4)\nrm(df_2022_q1, df_2022_q2, df_2022_q3, df_2022_q4)\ngc()\n\n\n          used (Mb) gc trigger  (Mb) limit (Mb)  max used   (Mb)\nNcells 1091833 58.4    3548442 189.6         NA   5544440  296.2\nVcells 9358549 71.5   94083848 717.9      16384 289322900 2207.4\n\n\nCode\n# Read 2023 data\ndf_2023_q1 &lt;- read_status_only(\"data/2023/FY2023_Q1.xlsx\", 2023)\ndf_2023_q2 &lt;- read_status_only(\"data/2023/FY2023_Q2.xlsx\", 2023)\ndf_2023_q3 &lt;- read_status_only(\"data/2023/FY2023_Q3.xlsx\", 2023)\ndf_2023_q4 &lt;- read_status_only(\"data/2023/FY2023_Q4.xlsx\", 2023)\ndf_2023 &lt;- bind_rows(df_2023_q1, df_2023_q2, df_2023_q3, df_2023_q4)\nrm(df_2023_q1, df_2023_q2, df_2023_q3, df_2023_q4)\ngc()\n\n\n           used (Mb) gc trigger  (Mb) limit (Mb)  max used   (Mb)\nNcells  1091885 58.4    3548442 189.6         NA   5544440  296.2\nVcells 10647825 81.3   79014404 602.9      16384 289322900 2207.4\n\n\nCode\n# Read 2024 data\ndf_2024_q1 &lt;- read_status_only(\"data/2024/FY2024_Q1.xlsx\", 2024)\ndf_2024_q2 &lt;- read_status_only(\"data/2024/FY2024_Q2.xlsx\", 2024)\ndf_2024_q3 &lt;- read_status_only(\"data/2024/FY2024_Q3.xlsx\", 2024)\ndf_2024_q4 &lt;- read_status_only(\"data/2024/FY2024_Q4.xlsx\", 2024)\ndf_2024 &lt;- bind_rows(df_2024_q1, df_2024_q2, df_2024_q3, df_2024_q4)\nrm(df_2024_q1, df_2024_q2, df_2024_q3, df_2024_q4)\ngc()\n\n\n           used (Mb) gc trigger  (Mb) limit (Mb)  max used   (Mb)\nNcells  1091940 58.4    3548442 189.6         NA   5544440  296.2\nVcells 11769967 89.8   88971206 678.8      16384 289322900 2207.4\n\n\nCode\n# Combine all years\nall_data &lt;- bind_rows(df_2019, df_2020, df_2021, df_2022, df_2023, df_2024)\n\n# Clear individual year dataframes\nrm(df_2019, df_2020, df_2021, df_2022, df_2023, df_2024)\ngc()\n\n\n           used (Mb) gc trigger  (Mb) limit (Mb)  max used   (Mb)\nNcells  1091930 58.4    3548442 189.6         NA   5544440  296.2\nVcells 11769972 89.8   71176965 543.1      16384 289322900 2207.4\n\n\nCode\n# Check the data\ncat(\"\\nTotal records loaded:\", nrow(all_data), \"\\n\")\n\n\n\nTotal records loaded: 3899983 \n\n\nCode\ncat(\"Unique case statuses:\", unique(all_data$CASE_STATUS), \"\\n\")\n\n\nUnique case statuses: WITHDRAWN CERTIFIED-WITHDRAWN CERTIFIED DENIED Certified Certified - Withdrawn Denied Withdrawn \n\n\nCode\n# Categorize case status into Accepted/Rejected\nall_data &lt;- all_data %&gt;%\n  mutate(STATUS_CATEGORY = case_when(\n    CASE_STATUS %in% c(\"Certified\", \"Certified - Withdrawn\") ~ \"Accepted\",\n    CASE_STATUS %in% c(\"Denied\", \"Withdrawn\") ~ \"Rejected\",\n    TRUE ~ \"Other\"\n  ))\n\n# Create summary by year and status\nsummary_data &lt;- all_data %&gt;%\n  filter(STATUS_CATEGORY %in% c(\"Accepted\", \"Rejected\")) %&gt;%\n  group_by(YEAR, STATUS_CATEGORY) %&gt;%\n  summarise(COUNT = n(), .groups = \"drop\")\n\n\n\n\nCode\n# Categorize case status into Accepted/Rejected\nall_data &lt;- all_data %&gt;%\n  mutate(STATUS_CATEGORY = case_when(\n    CASE_STATUS %in% c(\"Certified\", \"Certified - Withdrawn\", \"CERTIFIED\", \"CERTIFIED-WITHDRAWN\") ~ \"Accepted\",\n    CASE_STATUS %in% c(\"Denied\", \"Withdrawn\", \"DENIED\", \"WITHDRAWN\") ~ \"Rejected\",\n    TRUE ~ \"Other\"\n  ))\n\n# Create summary by year and status\nsummary_data &lt;- all_data %&gt;%\n  filter(STATUS_CATEGORY %in% c(\"Accepted\", \"Rejected\")) %&gt;%\n  group_by(YEAR, STATUS_CATEGORY) %&gt;%\n  summarise(COUNT = n(), .groups = \"drop\")\n# Print summary\nprint(all_data)\n\n\n# A tibble: 3,899,983 × 3\n   CASE_STATUS  YEAR STATUS_CATEGORY\n   &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;          \n 1 WITHDRAWN    2019 Rejected       \n 2 WITHDRAWN    2019 Rejected       \n 3 WITHDRAWN    2019 Rejected       \n 4 WITHDRAWN    2019 Rejected       \n 5 WITHDRAWN    2019 Rejected       \n 6 WITHDRAWN    2019 Rejected       \n 7 WITHDRAWN    2019 Rejected       \n 8 WITHDRAWN    2019 Rejected       \n 9 WITHDRAWN    2019 Rejected       \n10 WITHDRAWN    2019 Rejected       \n# ℹ 3,899,973 more rows\n\n\nCode\nprint(summary_data)\n\n\n# A tibble: 12 × 3\n    YEAR STATUS_CATEGORY  COUNT\n   &lt;dbl&gt; &lt;chr&gt;            &lt;int&gt;\n 1  2019 Accepted        639049\n 2  2019 Rejected         25567\n 3  2020 Accepted        562359\n 4  2020 Rejected         14975\n 5  2021 Accepted        805988\n 6  2021 Rejected         20317\n 7  2022 Accepted        611557\n 8  2022 Rejected         14527\n 9  2023 Accepted        630216\n10  2023 Rejected         14391\n11  2024 Accepted        547448\n12  2024 Rejected         13589\n\n\nCode\n# Create frequency histogram\nggplot(summary_data, aes(x = factor(YEAR), y = COUNT, fill = STATUS_CATEGORY)) +\n  geom_bar(stat = \"identity\", position = \"dodge\", width = 0.7) +\n  geom_text(aes(label = scales::comma(COUNT)), \n            position = position_dodge(width = 0.7), \n            vjust = -0.5, \n            size = 3.5) +\n  scale_fill_manual(values = c(\"Accepted\" = \"#2ecc71\", \"Rejected\" = \"#e74c3c\"),\n                    name = \"Status\") +\n  scale_y_continuous(labels = scales::comma, \n                     expand = expansion(mult = c(0, 0.1))) +\n  labs(title = \"H-1B Visa Filing Status by Year\",\n       subtitle = \"Frequency of Accepted vs Rejected Applications (FY 2019-2024)\",\n       x = \"Fiscal Year\",\n       y = \"Number of Applications\",\n       caption = \"Data Source: H-1B Disclosure Data\") +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(size = 16, face = \"bold\", hjust = 0.5),\n    plot.subtitle = element_text(size = 12, hjust = 0.5, color = \"gray40\"),\n    axis.title = element_text(size = 12, face = \"bold\"),\n    axis.text = element_text(size = 10),\n    legend.position = \"top\",\n    legend.title = element_text(face = \"bold\"),\n    panel.grid.minor = element_blank(),\n    panel.grid.major.x = element_blank()\n  )\n\n\n\n\n\n\n\n\n\nCode\n# Create additional percentage view\nsummary_data_pct &lt;- summary_data %&gt;%\n  group_by(YEAR) %&gt;%\n  mutate(PERCENTAGE = COUNT / sum(COUNT) * 100)\n\n# Print acceptance rates by year\nacceptance_rates &lt;- summary_data_pct %&gt;%\n  filter(STATUS_CATEGORY == \"Accepted\") %&gt;%\n  select(YEAR, PERCENTAGE) %&gt;%\n  mutate(PERCENTAGE = round(PERCENTAGE, 2))\n\ncat(\"\\nAcceptance Rates by Year:\\n\")\n\n\n\nAcceptance Rates by Year:\n\n\nCode\nprint(acceptance_rates)\n\n\n# A tibble: 6 × 2\n# Groups:   YEAR [6]\n   YEAR PERCENTAGE\n  &lt;dbl&gt;      &lt;dbl&gt;\n1  2019       96.2\n2  2020       97.4\n3  2021       97.5\n4  2022       97.7\n5  2023       97.8\n6  2024       97.6\n\n\nCode\n# Create stacked percentage bar chart\nggplot(summary_data_pct, aes(x = factor(YEAR), y = PERCENTAGE, fill = STATUS_CATEGORY)) +\n  geom_bar(stat = \"identity\", width = 0.7) +\n  geom_text(aes(label = paste0(round(PERCENTAGE, 1), \"%\")), \n            position = position_stack(vjust = 0.5), \n            size = 4, \n            color = \"white\",\n            fontface = \"bold\") +\n  scale_fill_manual(values = c(\"Accepted\" = \"#2ecc71\", \"Rejected\" = \"#e74c3c\"),\n                    name = \"Status\") +\n  labs(title = \"H-1B Visa Acceptance Rate by Year\",\n       subtitle = \"Percentage Distribution (FY 2019-2024)\",\n       x = \"Fiscal Year\",\n       y = \"Percentage (%)\",\n       caption = \"Data Source: H-1B Disclosure Data\") +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(size = 16, face = \"bold\", hjust = 0.5),\n    plot.subtitle = element_text(size = 12, hjust = 0.5, color = \"gray40\"),\n    axis.title = element_text(size = 12, face = \"bold\"),\n    axis.text = element_text(size = 10),\n    legend.position = \"top\",\n    legend.title = element_text(face = \"bold\"),\n    panel.grid.minor = element_blank(),\n    panel.grid.major.x = element_blank()\n  )\n\n\n\n\n\n\n\n\n\nThe analysis showed relatively stable volumes in most years, with accepted applications typically in the 550,000–650,000 range and rejected applications forming only a small fraction of the total. A notable aspect of the data is a prominent spike in accepted filings in FY 2021, where the count rises to more than 800,000 cases. This feature aligns with two well-documented contextual factors which are a rebound in employer demand following the initial COVID-19 hiring slowdown in 2020, and the introduction of the electronic H-1B registration system for the FY 2021 cap season, which reduced initial filing costs and made it easier for employers to submit registrations.\n\n\nCode\nlibrary(tidyr)\n\n\nlca &lt;- read_excel(\"data/2024/FY2024_Q4.xlsx\")\n\ncols_to_check &lt;- c(\n  \"CASE_STATUS\", \"RECEIVED_DATE\", \"VISA_CLASS\", \"FULL_TIME_POSITION\",\n  \"TOTAL_WORKER_POSITIONS\", \"JOB_TITLE\",\n  \"SOC_CODE\", \"SOC_TITLE\",\n  \"EMPLOYER_NAME\", \"EMPLOYER_STATE\", \"EMPLOYER_CITY\",\n  \"NAICS_CODE\",\n  \"WORKSITE_CITY\", \"WORKSITE_STATE\",\n  \"WAGE_RATE_OF_PAY_FROM\", \"WAGE_RATE_OF_PAY_TO\", \"WAGE_UNIT_OF_PAY\",\n  \"PREVAILING_WAGE\", \"PW_UNIT_OF_PAY\", \"PW_WAGE_LEVEL\"\n)\n\nmissing_summary &lt;- lca |&gt;\n  select(all_of(cols_to_check)) |&gt;\n  summarise(across(everything(), ~ mean(is.na(.)))) |&gt;\n  pivot_longer(everything(),\n               names_to = \"variable\",\n               values_to = \"prop_missing\")\n\nggplot(missing_summary,\n       aes(x = reorder(variable, prop_missing),\n           y = prop_missing)) +\n  geom_col() +\n  coord_flip() +\n  scale_y_continuous(labels = scales::percent_format()) +\n  labs(\n    x = \"Variable\",\n    y = \"Percent missing\",\n    title = \"Missingness by variable (key columns)\"\n  )\n\n\n\n\n\n\n\n\n\nThe plot visualising missing data for FY2024 Q4 shows that almost all of our key variables have no missing data for fields such as CASE_STATUS, employer and worksite location, SOC codes/titles, and most wage‐related variables. The main exceptions are WAGE_RATE_OF_PAY_TO, which has a noticable proportion of missing values, and PW_WAGE_LEVEL, which has a smaller but still significant amount of missingness. Because WAGE_RATE_OF_PAY_TO is often blank when a single wage value is reported, we focus primarily on WAGE_RATE_OF_PAY_FROM for our wage analyses.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data Analysis</span>"
    ]
  },
  {
    "objectID": "results.html",
    "href": "results.html",
    "title": "3  Experimentation and Results",
    "section": "",
    "text": "3.1 Preliminary Analysis\nAs specified during the data-set analysis, our overall extended analysis is limited towards the filings in FY-2024- Q4 (July 1 - September 31).\nCode\nlibrary(readxl)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(maps)\nlibrary(scales)\n\noptions(warn = -1)\n#reading the data\nlca &lt;- read_excel(\"data/2024/FY2024_Q4.xlsx\")",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Experimentation and Results</span>"
    ]
  },
  {
    "objectID": "results.html#preliminary-analysis",
    "href": "results.html#preliminary-analysis",
    "title": "3  Experimentation and Results",
    "section": "",
    "text": "3.1.1 Case Status\n\n\nCode\n#CASE STATUS Freq\ncase_freq &lt;- lca |&gt;\n  filter(!is.na(CASE_STATUS), CASE_STATUS != \"\") |&gt;\n  count(CASE_STATUS, sort = TRUE)\n\nggplot(case_freq, aes(x = reorder(CASE_STATUS, n), y = n)) +\n  geom_col() +\n  coord_flip() +\n  scale_y_continuous(labels = label_comma(scale = 1/1000, suffix = \"K\"))+\n  labs(\n    title = \"Frequency of CASE_STATUS in LCA Data\",\n    x = \"Case Status\",\n    y = \"No. of Applications (in Thousands)\"\n  ) + \n  theme_minimal()+\n   theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\nA vast majority of all LCA notifications are Certified, while a small percentage are either Certified-Withdrawn, Withdrawn, and even fewer are Denied. On the whole, it seems that the data indicates a predominant approval of LCAs, with direct rejections being a rather exceptional event.\n\n\n3.1.2 Prevailing Wage vs Case Status\n\n\nCode\n# Replace PREVAILING_WAGE with your actual wage column name if different\nlca_wage &lt;- lca |&gt;\nfilter(!is.na(PREVAILING_WAGE),\nPREVAILING_WAGE &gt; 0,\n!is.na(CASE_STATUS),\nCASE_STATUS != \"\")\n\nggplot(lca_wage, aes(x = CASE_STATUS, y = PREVAILING_WAGE)) +\ngeom_boxplot() +\ncoord_flip() +\n  scale_y_continuous(labels = label_comma(scale = 1/1000, suffix = \"K\"))+\nlabs(\ntitle = \"Prevailing Wage by Case Status\",\nx = \"Case Status\",\ny = \"Prevailing Wage (in Thousands)\"\n) +\ntheme_minimal()\n\n\n\n\n\n\n\n\n\nThe boxplot of prevailing wage by case status indicates that the wage distribution is almost the same in general through the four categories of outcome. For every status the wages’ central mass is approximately the same range, and most of the median values are around the mid-five-figure to low-six-figure level. The distributions are very much right-skewed and have a long upper tail of high-wage outliers, which is most pronounced in the certified and certified-withdrawn cases where the prevailing wage levels are extremely high for some observations. Denied and withdrawn cases show slight dispersion but toward lower wages, very little distinction made by prevailing wage between certified and non-certified applications during this period as indicated by the great overlap in the boxes and whiskers.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Experimentation and Results</span>"
    ]
  },
  {
    "objectID": "results.html#soc-selection-for-further-analysis",
    "href": "results.html#soc-selection-for-further-analysis",
    "title": "3  Experimentation and Results",
    "section": "3.2 SOC Selection for Further Analysis",
    "text": "3.2 SOC Selection for Further Analysis\nWe start our further analysis by identifying the top SOCs in-terms of highest frequency and higher median wages.\n\n3.2.1 SOC Frequency Analysis\nThe below experiments are to identify the SOC groups with highest frequency of filings in 2024 Q4.\n\n\nCode\n#Frequency of SOCs\nsoc_freq &lt;- lca |&gt;\n  filter(!is.na(SOC_TITLE), SOC_TITLE != \"\") |&gt;\n  count(SOC_TITLE, sort = TRUE)\n#SOC vs Freq\nsoc_freq|&gt;\n  slice_max(n, n = 20) |&gt;\n  ggplot(aes(x = reorder(SOC_TITLE, n), y = n)) +\n  geom_col() +\n  coord_flip() +\n  scale_y_continuous(labels = label_comma(scale = 1/1000, suffix = \"K\")) +\n  labs(\n    title = \"Frequency of SOC in LCA Data\",\n    x = \"SOC\",\n    y = \"No of Applications (in Thousands)\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nCode\nsoc_table_top20 &lt;- lca |&gt;\n  count(SOC_CODE, SOC_TITLE, name = \"n\") |&gt;\n  slice_max(n, n = 20, with_ties = FALSE) |&gt;\n  arrange(desc(n))\n\nsoc_table_top20\n\n\n# A tibble: 20 × 3\n   SOC_CODE   SOC_TITLE                                           n\n   &lt;chr&gt;      &lt;chr&gt;                                           &lt;int&gt;\n 1 15-1252.00 Software Developers                             38051\n 2 15-1299.08 Computer Systems Engineers/Architects            7629\n 3 15-1299.09 Information Technology Project Managers          4673\n 4 15-1253.00 Software Quality Assurance Analysts and Testers  3858\n 5 15-1211.00 Computer Systems Analysts                        3251\n 6 11-3021.00 Computer and Information Systems Managers        2959\n 7 15-2051.00 Data Scientists                                  2715\n 8 15-1251.00 Computer Programmers                             2650\n 9 15-2051.01 Business Intelligence Analysts                   2205\n10 17-2141.00 Mechanical Engineers                             1977\n11 15-2031.00 Operations Research Analysts                     1641\n12 13-2011.00 Accountants and Auditors                         1546\n13 19-1042.00 Medical Scientists, Except Epidemiologists       1470\n14 17-2071.00 Electrical Engineers                             1436\n15 13-2051.00 Financial and Investment Analysts                1422\n16 15-1242.00 Database Administrators                          1355\n17 17-2072.00 Electronics Engineers, Except Computer           1337\n18 17-2112.00 Industrial Engineers                             1125\n19 13-1111.00 Management Analysts                              1113\n20 17-2051.00 Civil Engineers                                   985\n\n\nFrom the above analysis it is evident that Software Developers (15-1251, 15-1252) attributes to be the highest SOC group to be filed in 2024 Q4. The Frequency distribution clearly shows the skew towards filings for more IT/Software/Computer Science/Analytics related roles and the top 20 SOCs clearly depicts the most H1B filings for Tech roles.\nThe large disparity that we see between the Software Developer SOC and the rest can be explained by the broader range of job types/categories that it covers (eg: entry-level, associates, etc.), In contrast, the other SOC roles tend to be more niche and hierarchy, resulting in fewer openings/applicants.\n\n\n3.2.2 SOC Wage Analysis\nNext we experimented by performing a wage analysis for different SOCs, to identify the top paying SOCs and in order to do this analysis we leverage box plot to analyze the mean wages. However, in our preliminary analysis we found inconsistencies in the wage format, since wages are reported in different units (year, month, week, hour). Therefore, we restricted our analysis to the hourly and yearly wages, which have the largest number of observations.\n\n\nCode\n# Keep only rows with needed fields\nlca_clean &lt;- lca |&gt;\n  filter(\n    !is.na(SOC_TITLE),\n    !is.na(WAGE_RATE_OF_PAY_FROM),\n    !is.na(PW_UNIT_OF_PAY)\n  )\n\n# Top 20 SOC titles in this cleaned data\ntop_20_soc_titles &lt;- lca_clean |&gt;\n  count(SOC_TITLE, sort = TRUE) |&gt;\n  slice_head(n = 20) |&gt;\n  pull(SOC_TITLE)\n\nlca_clean |&gt;\n  filter(SOC_TITLE %in% top_20_soc_titles) |&gt;\n  count(PW_UNIT_OF_PAY)\n\n\n# A tibble: 5 × 2\n  PW_UNIT_OF_PAY     n\n  &lt;chr&gt;          &lt;int&gt;\n1 Bi-Weekly          9\n2 Hour            3742\n3 Month             36\n4 Week               6\n5 Year           80877\n\n\nLets analyze the median distribution of wages for different SOCs.\n\n\nCode\n# Keep only rows with needed fields\n\n# Read data\nlca_clean &lt;- lca |&gt;\n  filter(\n    !is.na(SOC_TITLE),\n    !is.na(WAGE_RATE_OF_PAY_FROM),\n    !is.na(PW_UNIT_OF_PAY)\n  )\n\n# Top 20 SOC titles\ntop_20_soc_titles &lt;- lca_clean |&gt;\n  count(SOC_TITLE, sort = TRUE) |&gt;\n  slice_head(n = 20) |&gt;\n  pull(SOC_TITLE)\n\n# Filter for top 20 with sufficient data\nlca_top20 &lt;- lca_clean |&gt;\n  filter(SOC_TITLE %in% top_20_soc_titles) |&gt;\n  group_by(SOC_TITLE, PW_UNIT_OF_PAY) |&gt;\n  filter(n() &gt;= 50) |&gt;\n  ungroup()\n\n# Identify and remove outliers using IQR method\nlca_no_outliers &lt;- lca_top20 |&gt;\n  group_by(SOC_TITLE, PW_UNIT_OF_PAY) |&gt;\n  mutate(\n    Q1 = quantile(WAGE_RATE_OF_PAY_FROM, 0.25),\n    Q3 = quantile(WAGE_RATE_OF_PAY_FROM, 0.75),\n    IQR = Q3 - Q1,\n    lower_bound = Q1 - 1.5 * IQR,\n    upper_bound = Q3 + 1.5 * IQR,\n    is_outlier = WAGE_RATE_OF_PAY_FROM &lt; lower_bound | WAGE_RATE_OF_PAY_FROM &gt; upper_bound\n  ) |&gt;\n  ungroup()\n\n# Store outliers for later\noutliers_data &lt;- lca_no_outliers |&gt;\n  filter(is_outlier) |&gt;\n  select(SOC_TITLE, PW_UNIT_OF_PAY, WAGE_RATE_OF_PAY_FROM, EMPLOYER_NAME, CASE_NUMBER) |&gt;\n  arrange(desc(WAGE_RATE_OF_PAY_FROM))\n\n# Plot without outliers\nlca_no_outliers |&gt;\n  filter(!is_outlier) |&gt;\n  ggplot(aes(\n    x = reorder(SOC_TITLE, WAGE_RATE_OF_PAY_FROM, FUN = median),\n    y = WAGE_RATE_OF_PAY_FROM\n  )) +\n  geom_boxplot() +\n  coord_flip() +\n  facet_wrap(~ PW_UNIT_OF_PAY, scales = \"free_x\") +\n  scale_y_continuous(labels = label_comma(scale = 1/1000, suffix = \"K\")) +\n  labs(\n    x = \"SOC Title\",\n    y = \"Wage Rate of Pay (FROM) - Thousands\",\n    title = \"Wage Distribution by SOC (Top 20, Faceted by Pay Unit)\",\n    subtitle = paste(\"Outliers removed:\", format(nrow(outliers_data), big.mark = \",\"), \"cases\")\n  ) +\n  theme(\n    text = element_text(size = 14),\n    axis.text = element_text(size = 12),\n    axis.title = element_text(size = 14, face = \"bold\"),\n    plot.title = element_text(size = 16, face = \"bold\"),\n    plot.subtitle = element_text(size = 13),\n    strip.text = element_text(size = 13, face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\nThe wage distribution plot indicates that, after removing extreme outliers, wages for the top 20 SOC titles are grouped closely together. Most of the annual salaries are within a similar mid-to-upper range, showing only slight differences between higher- and lower-paid jobs. However, within each SOC, the boxes and whiskers are relatively tall which means that there is significant variability within occupations and workers in the same job category can earn different amounts, even when using the same pay unit. Comparing hourly and yearly income shows that the overall ranking of jobs remains generally the same across pay units. However, the hourly panel has slightly less variation.\n\n\nCode\n# Summary table of outliers\noutliers_summary &lt;- lca_no_outliers |&gt;\n  filter(is_outlier) |&gt;\n  group_by(SOC_TITLE, PW_UNIT_OF_PAY) |&gt;\n  summarise(\n    n_outliers = n(),\n    min_outlier_wage = min(WAGE_RATE_OF_PAY_FROM),\n    max_outlier_wage = max(WAGE_RATE_OF_PAY_FROM),\n    upper_bound_threshold = first(upper_bound),\n    lower_bound_threshold = first(lower_bound),\n    .groups = \"drop\"\n  ) |&gt;\n  arrange(desc(max_outlier_wage))\n\nprint(\"Summary of removed outliers:\")\n\n\n[1] \"Summary of removed outliers:\"\n\n\nCode\noutliers_summary |&gt;\n  head(10)\n\n\n# A tibble: 10 × 7\n   SOC_TITLE         PW_UNIT_OF_PAY n_outliers min_outlier_wage max_outlier_wage\n   &lt;chr&gt;             &lt;chr&gt;               &lt;int&gt;            &lt;dbl&gt;            &lt;dbl&gt;\n 1 Software Develop… Year                  388         260040         140213006 \n 2 Information Tech… Year                   62             62.5        14369524 \n 3 Computer Systems… Year                  139         205731.          1515180 \n 4 Medical Scientis… Year                  143         130000           1228250 \n 5 Financial and In… Year                   30             38           1000000 \n 6 Data Scientists   Year                   25            110            785690.\n 7 Computer and Inf… Year                   50         320000            537152.\n 8 Management Analy… Year                   21         268400            400000 \n 9 Operations Resea… Year                   25         270000            384000 \n10 Business Intelli… Year                   26         234000            376000 \n# ℹ 2 more variables: upper_bound_threshold &lt;dbl&gt;, lower_bound_threshold &lt;dbl&gt;\n\n\n\n\n3.2.3 Top SOCs vs States\n\n\nCode\n# Step 1: Filter and count (select only needed columns first for memory efficiency)\nsoc_state &lt;- lca |&gt;\n  select(SOC_TITLE, WORKSITE_STATE) |&gt;\n  filter(!is.na(SOC_TITLE), SOC_TITLE != \"\",\n         !is.na(WORKSITE_STATE), WORKSITE_STATE != \"\") |&gt;\n  count(SOC_TITLE, WORKSITE_STATE, name = \"n\")\n\n# Step 2: Get top 10 SOC titles\ntop_soc &lt;- soc_state |&gt;\n  group_by(SOC_TITLE) |&gt;\n  summarise(total = sum(n), .groups = \"drop\") |&gt;\n  slice_max(total, n = 10, with_ties = FALSE)\n\n# Step 3: Get top 10 states (from top SOCs only)\ntop_states &lt;- soc_state |&gt;\n  semi_join(top_soc, by = \"SOC_TITLE\") |&gt;\n  group_by(WORKSITE_STATE) |&gt;\n  summarise(total = sum(n), .groups = \"drop\") |&gt;\n  slice_max(total, n = 10, with_ties = FALSE)\n\n# Step 4: Calculate proportions\nsoc_state_prop &lt;- soc_state |&gt;\n  semi_join(top_soc, by = \"SOC_TITLE\") |&gt;\n  semi_join(top_states, by = \"WORKSITE_STATE\") |&gt;\n  group_by(SOC_TITLE) |&gt;\n  mutate(share = n / sum(n)) |&gt;\n  ungroup()\n\n# Step 5: Heatmap\nggplot(soc_state_prop,\n       aes(x = WORKSITE_STATE, y = SOC_TITLE, fill = share)) +\n  geom_tile(color = \"white\", linewidth = 0.5) +  # Added borders for clarity\n  scale_fill_gradient(\n    low  = \"white\",\n    high = \"darkblue\",\n    labels = percent_format(accuracy = 1)\n  ) +\n  labs(\n    title = \"Where Are Top SOC Titles Concentrated?\",\n    x = \"State\",\n    y = \"SOC Title\",\n    fill = \"Share of\\nSOC in State\"\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1, size = 10),\n    axis.text.y = element_text(size = 9),\n    plot.title = element_text(face = \"bold\", size = 14)\n  )\n\n\n\n\n\n\n\n\n\nThe heatmap represents the LCA distribution of the ten most common SOC titles in the ten states with the highest volume. Some patterns of concentrations are very clear. Software roles like Software Developers, Computer Systems Engineers/Architects, and Computer Programmers occupy predominantly large tech hubs, mainly California and Texas, followed by noticeably but smaller shares in other states like New York, Washington, and Virginia. Similarly, Data-related occupations like Data Scientists and Business Intelligence Analysts are mostly found in these coastal and highly tech states. On the other hand, some titles, like Mechanical Engineers and Information Technology Project Managers, are more dispersed and thus less concentrated hence the light but even shading. All in all, the figure shows that a small number of states contributes a lot to the H-1B LCAs in the technology occupations that are critical.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Experimentation and Results</span>"
    ]
  },
  {
    "objectID": "results.html#analysis-for-software-developer-soc",
    "href": "results.html#analysis-for-software-developer-soc",
    "title": "3  Experimentation and Results",
    "section": "3.3 Analysis for Software Developer SOC",
    "text": "3.3 Analysis for Software Developer SOC\n\n3.3.1 Job Title Frequency Analysis\n\n\nCode\n# 1. Filter only SOC = \"Software Developers\"\nsoftware_dev &lt;- lca %&gt;%\n  filter(SOC_TITLE == \"Software Developers\")\n\n# 2. Get frequency of job titles within this SOC\njob_freq &lt;- software_dev %&gt;%\n  filter(!is.na(JOB_TITLE), JOB_TITLE != \"\") %&gt;%\n  count(JOB_TITLE, sort = TRUE)\n\n# 3. Bar chart of top 20 job titles in Software Developers SOC\njob_freq |&gt;\n  slice_max(n, n = 20) |&gt;   \n  ggplot(aes(x = reorder(JOB_TITLE, n), y = n)) +\n  geom_col() +\n  coord_flip() +\n  scale_y_continuous(labels = label_comma(scale = 1/1000, suffix = \"K\")) +\n  labs(\n    title = \"Top Job Titles within SOC: Software Developers\",\n    x = \"Job Title\",\n    y = \"No of Applications (in Thousands)\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n3.3.2 Case Status Distribution\n\n\nCode\njob_case &lt;- software_dev |&gt;\n  filter(!is.na(JOB_TITLE), JOB_TITLE != \"\",\n         !is.na(CASE_STATUS), CASE_STATUS != \"\") |&gt;\n  count(JOB_TITLE, CASE_STATUS, name = \"n\")\n\n# Focus on top 10 job titles overall\ntop10_jobs &lt;- job_freq |&gt;\n  slice_max(n, n = 10) |&gt;\n  pull(JOB_TITLE)\n\njob_case_top &lt;- job_case |&gt;\n  filter(JOB_TITLE %in% top10_jobs) |&gt;\n  group_by(JOB_TITLE) |&gt;\n  mutate(total_n = sum(n)) |&gt;   # total count for that job title\n  ungroup()\n\nggplot(job_case_top,\n       aes(x = reorder(JOB_TITLE, total_n), y = n, fill = CASE_STATUS)) +\n  geom_col() +\n  coord_flip() +\n  labs(\n    title = \"Case Status Distribution\\nTop 10 Job Titles (Software Developers)\",\n    x = \"Job Title\",\n    y = \"Count\",\n    fill = \"Case Status\"\n  ) +\n  scale_fill_manual(\n    values = c(\n      \"Certified\"            = \"#B4EEB4\",\n      \"Denied\"               = \"red\",\n      \"Withdrawn\"            = \"orange\",\n      \"Certified - Withdrawn\" = \"steelblue\"\n    )\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nThe distribution of case statuses within the top ten job titles under the “Software Developers” SOC shows that applications are overwhelmingly Certified across all titles. Roles such as Software Engineer, Software Developer, and Software Engineering account for the largest volumes, with only a very small share of cases appearing as Denied or Withdrawn. “Certified – Withdrawn” cases are present but remain a minor component relative to straightforward certifications. Overall, the figure indicates that for the most common software-developer job titles, H-1B LCA filings in this quarter are both highly concentrated in a small set of titles and have very high approval rates.\n\n\n3.3.3 State-wise Application Acceptance Analysis\n\n\nCode\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(maps)\n\n# Filter for Software Developer SOC codes and calculate certification rate BY STATE\nstate_cert_rate &lt;- lca |&gt;\n  filter(!is.na(WORKSITE_STATE), WORKSITE_STATE != \"\") |&gt;\n  filter(grepl(\"Software Developers\", SOC_TITLE)) |&gt;  # Software Developer SOC codes\n  group_by(WORKSITE_STATE) |&gt;\n  summarise(\n    total_cases = n(),\n    certified_cases = sum(CASE_STATUS == \"Certified\", na.rm = TRUE),\n    cert_rate = (certified_cases / total_cases) * 100,\n    .groups = \"drop\"\n  )\n\n# Lookup table: 2-letter abbrev -&gt; full state name (lowercase for map_data)\nstate_lookup &lt;- data.frame(\n  WORKSITE_STATE = state.abb,\n  region = tolower(state.name),\n  stringsAsFactors = FALSE\n)\n\n# Join certification rates with state names and create bins\nstate_cert_map &lt;- state_cert_rate |&gt;\n  inner_join(state_lookup, by = \"WORKSITE_STATE\") |&gt;\n  mutate(cert_bin = cut(cert_rate, \n                        breaks = c(0, 70, 80, 85, 90, 95, 100),\n                        labels = c(\"&lt; 70%\", \"70-80%\", \"80-85%\", \"85-90%\", \"90-95%\", \"95-100%\"),\n                        include.lowest = TRUE))\n\n# Get USA map data\nusa_map &lt;- map_data(\"state\")\n\n# Combine map with certification data\nplot_data &lt;- usa_map |&gt;\n  left_join(state_cert_map, by = \"region\")\n\n# Calculate state label positions\nstate_labels &lt;- plot_data |&gt;\n  group_by(region) |&gt;\n  summarise(\n    long = mean(range(long)),\n    lat = mean(range(lat)),\n    .groups = \"drop\"\n  ) |&gt;\n  left_join(state_cert_map, by = \"region\")\n\n# Choropleth Map with Discrete Binned Colors\nggplot() +\n  geom_polygon(\n    data = plot_data,\n    aes(x = long, y = lat, group = group, fill = cert_bin),\n    color = \"black\",\n    linewidth = 0.2\n  ) +\n  geom_text(\n    data = state_labels |&gt; filter(!is.na(WORKSITE_STATE)),\n    aes(x = long, y = lat, label = WORKSITE_STATE),\n    color = \"black\",\n    size = 2.5,\n    fontface = \"bold\"\n  ) +\n  coord_fixed(1.3) +\n  scale_fill_brewer(\n    palette = \"RdYlGn\",\n    na.value = \"grey90\",\n    direction = 1\n  ) +\n  labs(\n    title = \"LCA Certification Rate by State - Software Developers\",\n    subtitle = \"Percentage of applications certified within each state\",\n    fill = \"Certification\\nRate\",\n    x = NULL,\n    y = NULL\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text = element_blank(),\n    axis.ticks = element_blank(),\n    panel.grid = element_blank(),\n    plot.title = element_text(face = \"bold\", size = 14),\n    plot.subtitle = element_text(size = 11, color = \"grey40\"),\n    legend.position = \"right\"\n  )\n\n\n\n\n\n\n\n\n\nThe map shows that most states have very high certification rates for Software Developer LCAs (generally above 90%), especially major tech states like CA, WA, TX, and NY. A small number of states fall into lower bands (below about 85–90%), indicating that denials are relatively uncommon for this occupation in most of the country. Only South Dakota (about 70–80%) and North Dakota (below 70%) stand out with noticeably lower certification rates.\n\n\n3.3.4 State-wise Wage Distribution Analysis\n\n\nCode\nstate_wage &lt;- lca |&gt;\n  filter(\n    CASE_STATUS == \"Certified\",\n    SOC_TITLE == \"Software Developers\",\n    !is.na(WORKSITE_STATE),\n    WORKSITE_STATE != \"\",\n    !is.na(PREVAILING_WAGE),\n    PREVAILING_WAGE &gt; 0\n  ) |&gt;\n  group_by(WORKSITE_STATE) |&gt;\n  summarise(\n    median_wage = median(PREVAILING_WAGE),\n    .groups = \"drop\"\n  )\n\nstate_wage_map &lt;- state_wage |&gt;\n  inner_join(state_lookup, by = \"WORKSITE_STATE\")\n\nusa_map &lt;- map_data(\"state\")\n\nplot_wage_data &lt;- usa_map |&gt;\n  left_join(state_wage_map, by = \"region\")\n\nmid_val &lt;- median(plot_wage_data$median_wage, na.rm = TRUE)\n\n\nggplot() +\n  geom_polygon(\n    data = plot_wage_data,\n    aes(x = long, y = lat, group = group, fill = median_wage),\n    color = \"white\",\n    linewidth = 0.2\n  ) +\n  geom_text(\n    data = state_labels,\n    aes(x = long, y = lat, label = WORKSITE_STATE),\n    color = \"white\",\n    size  = 2\n  ) +\n  coord_fixed(1.3) +\n  labs(\n    title = \"Median Prevailing Wage by State (Certified LCAs)\",\n    fill  = \"Median Wage\",\n    x = NULL,\n    y = NULL\n  ) +\n  scale_fill_gradient(\n    low  = \"#c6e5ff\",\n    high = \"#003366\",\n    trans = \"sqrt\"  \n  ) +\n  theme_minimal() +\n  theme(\n    axis.text  = element_blank(),\n    axis.ticks = element_blank()\n  )\n\n\n\n\n\n\n\n\n\nThe map of median prevailing wage for certified LCAs presents a distinct pattern of distribution across the country. The top-ranked median salaries are found in the coastal and states with technology as the main industry like California, Washington, and New York where the median values are above $150,000. Other states with very high median wages are Massachusetts and a few western states with big cities that have a large labor market. On the other hand, the southern and to some extent, the midwestern states have noticeably lower median prevailing wages, mostly between $70,000 and $100,000. This distribution not only mirrors differences in local cost of living and industrial composition but also, in high-cost, tech-heavy areas, H-1B workers are paid higher than in states where a larger share of the workforce is in lower-paying occupations.\n\n\n3.3.5 Alluvial\n\n\nCode\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(ggalluvial)\n\n# Filter for Software Developers\nsoftware_dev &lt;- lca |&gt;\n  filter(SOC_TITLE == \"Software Developers\")\n\n# Get top 10 job titles\ntop_job_titles &lt;- software_dev |&gt;\n  filter(!is.na(JOB_TITLE), JOB_TITLE != \"\") |&gt;\n  count(JOB_TITLE, sort = TRUE) |&gt;\n  slice_head(n = 10) |&gt;\n  pull(JOB_TITLE)\n\n# Create the flow data with top job titles only\nsoftware_dev_flow &lt;- software_dev |&gt;\n  filter(\n    JOB_TITLE %in% top_job_titles,\n    !is.na(PW_WAGE_LEVEL), PW_WAGE_LEVEL != \"\",\n    !is.na(CASE_STATUS), CASE_STATUS != \"\",\n    CASE_STATUS %in% c(\"Denied\", \"Withdrawn\", \"Certified - Withdrawn\")\n  ) |&gt;\n  count(JOB_TITLE, PW_WAGE_LEVEL, CASE_STATUS, name = \"n\") |&gt;\n  filter(n &gt; 20)  # Lower threshold since we're already filtering to top titles\n\n# Create alluvial diagram\nggplot(software_dev_flow,\n       aes(axis1 = JOB_TITLE,\n           axis2 = PW_WAGE_LEVEL,\n           axis3 = CASE_STATUS,\n           y = n)) +\n  geom_alluvium(aes(fill = PW_WAGE_LEVEL), alpha = 0.7) +\n  geom_stratum() +\n  geom_text(stat = \"stratum\",\n            aes(label = after_stat(stratum)), size = 2.5) +\n  scale_x_discrete(limits = c(\"Job Title\", \"PW Wage Level\", \"Case Status\")) +\n  scale_fill_brewer(palette = \"Set2\") +\n  labs(\n    title = \"Flow from Top Software Developer Job Titles to Wage Level to Case Status\",\n    subtitle = \"Top 10 most common job titles for Software Developers\",\n    y = \"Number of Cases\",\n    fill = \"Wage Level\"\n  ) +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(face = \"bold\", size = 14),\n    plot.subtitle = element_text(size = 11, color = \"grey40\"),\n    axis.text.x = element_text(size = 10, face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\nThe alluvial diagram shows how non-certified cases for the top Software Developer job titles flow through wage levels to final outcomes. Most of these cases are filed at prevailing wage level II, with smaller shares at levels I and III; level III is more common for senior titles such as Senior Software Engineer. Across wage levels, the predominant outcome is “Certified – Withdrawn”, while outright denials and withdrawals are relatively rare, indicating that most problematic cases for these titles are not rejected by the agency but instead withdrawn after certification or during processing.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Experimentation and Results</span>"
    ]
  },
  {
    "objectID": "results.html#model-analysis",
    "href": "results.html#model-analysis",
    "title": "3  Experimentation and Results",
    "section": "3.4 Model Analysis",
    "text": "3.4 Model Analysis\n\n\nCode\nlibrary(dplyr)\nlibrary(rpart)\nlibrary(rpart.plot)\n\n# Prepare data\nlca_simple &lt;- lca |&gt;\n  filter(!is.na(CASE_STATUS)) |&gt;\n  mutate(\n    certified = factor(ifelse(CASE_STATUS == \"Certified\", \"Yes\", \"No\")),\n    wage_level = factor(coalesce(PW_WAGE_LEVEL, \"Unknown\")),\n    soc_major = factor(substr(SOC_CODE, 1, 2)),\n    state_group = case_when(\n      WORKSITE_STATE %in% c(\"CA\", \"TX\", \"NY\", \"WA\", \"NJ\") ~ WORKSITE_STATE,\n      TRUE ~ \"Other\"\n    ),\n    state_group = factor(state_group),\n    full_time = factor(ifelse(FULL_TIME_POSITION == \"Y\", \"Yes\", \"No\"))\n  ) |&gt;\n  select(certified, wage_level, soc_major, state_group, full_time) |&gt;\n  na.omit()\n\n# Sample data\nset.seed(123)\nif(nrow(lca_simple) &gt; 20000) {\n  lca_simple &lt;- lca_simple |&gt; slice_sample(n = 20000)\n}\n\n# Split data\ntrain_idx &lt;- sample(1:nrow(lca_simple), 0.7 * nrow(lca_simple))\ntrain &lt;- lca_simple[train_idx, ]\ntest &lt;- lca_simple[-train_idx, ]\n\n# Check class balance\ncat(\"Training set class distribution:\\n\")\n\n\nTraining set class distribution:\n\n\nCode\nprint(table(train$certified))\n\n\n\n   No   Yes \n 1259 12741 \n\n\nCode\nprint(prop.table(table(train$certified)))\n\n\n\n        No        Yes \n0.08992857 0.91007143 \n\n\nCode\n# Calculate class weights to handle imbalance\nn_yes &lt;- sum(train$certified == \"Yes\")\nn_no &lt;- sum(train$certified == \"No\")\ntotal &lt;- nrow(train)\n\n# Create loss matrix to penalize misclassifying minority class more\nloss_matrix &lt;- matrix(c(0, n_yes/n_no, 1, 0), nrow = 2, byrow = TRUE)\nrownames(loss_matrix) &lt;- c(\"No\", \"Yes\")\ncolnames(loss_matrix) &lt;- c(\"No\", \"Yes\")\n\n# Train Decision Tree with loss matrix\ntree_model &lt;- rpart(\n  certified ~ .,\n  data = train,\n  method = \"class\",\n  parms = list(loss = loss_matrix),\n  control = rpart.control(\n    maxdepth = 5, \n    minsplit = 30,    # Lower to allow more splits\n    minbucket = 10,   # Lower minimum leaf size\n    cp = 0.0001       # Much lower complexity parameter\n  )\n)\n\n# Visualize tree\nrpart.plot(tree_model, under = TRUE)\n\n\n\n\n\n\n\n\n\nThe decision tree models the probability that an LCA is certified using only a few discrete predictors: SOC major group, grouped worksite state, prevailing wage level, and full-time status. The root node already reflects the strong imbalance in the data, with roughly 90% of cases certified overall, so most terminal nodes also have high certification probabilities. The first splits show that certification is especially likely for certain SOC clusters filed in CA, NY, NJ, TX or WA and at standard wage levels (I or IV), where the predicted certification rate is typically above 90–95%. Lower certification probabilities appear only in small subgroups—mainly some non-tech SOC groups in “Other” states or records with non-standard/unknown wage levels—indicating that, conditional on these features, denial remains relatively rare.\n\n\nCode\n# Model accuracy\npredictions &lt;- predict(tree_model, test, type = \"class\")\naccuracy &lt;- mean(predictions == test$certified)\ncat(\"Accuracy:\", round(accuracy, 4), \"\\n\")\n\n\nAccuracy: 0.6585 \n\n\nCode\n# Confusion Matrix\nconf_matrix &lt;- table(Predicted = predictions, Actual = test$certified)\nprint(conf_matrix)\n\n\n         Actual\nPredicted   No  Yes\n      No   254 1755\n      Yes  294 3697\n\n\n\n\nCode\n# Feature Importance (from rpart)\nimportance &lt;- tree_model$variable.importance\n\nif(length(importance) &gt; 0) {\n  importance_df &lt;- data.frame(\n    Feature = names(importance),\n    Importance = importance\n  ) |&gt;\n    arrange(desc(Importance))\n  \n  library(ggplot2)\n  ggplot(importance_df, aes(x = reorder(Feature, Importance), y = Importance)) +\n    geom_col(fill = \"steelblue\", alpha = 0.8) +\n    coord_flip() +\n    labs(\n      title = \"Feature Importance from Decision Tree\",\n      x = \"Feature\",\n      y = \"Importance Score\"\n    ) +\n    theme_minimal()\n} else {\n  cat(\"No variable importance available - tree may not have splits\\n\")\n}\n\n\n\n\n\n\n\n\n\nThe plot shows feature-importance of predictors used by the decision tree. It is evident that the SOC major group (soc_major) is the most influential predictor of whether an LCA is certified. Next is the worksite location (state_group), followed by the prevailing wage level (wage_level). The full-time indicator (full_time) has very low importance. This suggests that, in this model, the type of occupation and its location matter much more for certification outcomes than whether the position is classified as full-time.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Experimentation and Results</span>"
    ]
  },
  {
    "objectID": "conclusion.html",
    "href": "conclusion.html",
    "title": "4  Conclusion",
    "section": "",
    "text": "This analysis used LCA public disclosures (2019–2024) to provide an in-depth look at H-1B and related work-visa applications along geographical, occupational, temporal, and employer lines, as well as process outcomes. Throughout the analysis a lot of common threads can be observed. First, approval is the dominant outcome at the LCA stage: certified (or certified-withdrawn) cases outnumber denials and withdrawals by roughly nine to one. The sharp increase in filings in FY 2021 stands out against otherwise stable volumes and is consistent with a post-pandemic hiring rebound and procedural changes, while approval rates remain high.\nLocation is a second key dimension. Approvals and high prevailing wages are concentrated in a small set of tech-intensive regions especially coastal hubs such as California, Washington, New York, Texas, and parts of the Northeast which also host a disproportionate share of high-skill SOC categories in software and data. At the same time, the software-developer certification map shows very high approval rates in almost all states, with only a few pockets of lower rates, suggesting that geography shapes wage levels and filing volumes more than the probability of certification.\nOccupational structure matters more than specific job titles. SOC-level wage distributions show that analytical and IT occupations tend to earn higher salaries, but there is substantial within-occupation dispersion and broad overlap across SOCs once outliers are removed. Boxplots and alluvial diagrams indicate differences in wage levels across outcomes, but these do not sharply separate certified from non-certified cases; many non-standard outcomes are certified-withdrawn rather than outright denials. The decision-tree model confirms this pattern: the most important predictors of certification are SOC major group and worksite location, with prevailing wage level playing a secondary role and full-time status contributing very little. Even within subgroups defined by the tree, predicted certification probabilities remain high.\nThe application process itself is highly skewed and hierarchical. For software-developer roles, flows from job title to wage level to status show that a small number of common titles and mid-range wage levels account for most cases, and most of these proceed smoothly to certification, with only a minority diverted into withdrawal or denial. Data-quality checks indicate that core variables like case status, SOC codes and titles, wages, and locations are largely complete, with missingness concentrated in secondary fields such as upper wage bounds and some prevailing-wage metadata. However, LCAs capture only one step in a multi-stage visa process, wages are reported in heterogeneous units, and the observational nature of the data precludes causal claims about what drives certification.\nOverall, the findings suggest that LCA outcomes at the DOL stage are shaped more by structural factors such as occupation mix, geography, and broad wage tiers than by fine-grained differences in job title or full-time status, and that the main variation lies in where and for which occupations employers file large numbers of applications rather than in whether those applications are approved. These patterns provide a baseline for future work, including CBSA-level analyses, measures of employer concentration, and richer models that incorporate additional wage and occupational detail.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Conclusion</span>"
    ]
  }
]